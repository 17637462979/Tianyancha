{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 输入查询公司的名称，支持模糊搜索和简称，如“中信”\n",
        "keyword = '中信'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "import time,re,os\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "path = os.getcwd().replace('\\\\','/')+'/'\n",
        "\n\n",
        "def open_browser(url):\n",
        "    driver = webdriver.Chrome()\n",
        "    driver.get(url)\n",
        "    return driver\n",
        "\n\n",
        "def log_in(driver):\n",
        "    # 模拟登陆\n",
        "    driver.find_element_by_xpath(\n",
        "        \".//*[@id='web-content']/div/div/div/div[2]/div/div[2]/div[2]/div[2]/div[2]/input\"). \\\n",
        "        send_keys(username)\n",
        "    driver.find_element_by_xpath(\n",
        "        \".//*[@id='web-content']/div/div/div/div[2]/div/div[2]/div[2]/div[2]/div[3]/input\"). \\\n",
        "        send_keys(password)\n",
        "    driver.find_element_by_xpath(\n",
        "        \".//*[@id='web-content']/div/div/div/div[2]/div/div[2]/div[2]/div[2]/div[5]\").click()\n",
        "    time.sleep(3)\n",
        "    return driver\n",
        "\n\n",
        "def search_company(driver, url1):\n",
        "    driver.get(url1)\n",
        "    content = driver.page_source.encode('utf-8')\n",
        "    soup1 = BeautifulSoup(content, 'lxml')\n",
        "    time.sleep(3)\n",
        "    # company_name = soup1.find('a', class_=\"query_name sv-search-company f18 in-block vertical-middle\").get_text()\n",
        "\n",
        "    url2 = soup1.find('a', class_=\"query_name sv-search-company f18 in-block vertical-middle\").attrs['href']\n",
        "    driver.get(url2)\n",
        "    # content2 = driver.page_source.encode('utf-8')\n",
        "    # soup2 = BeautifulSoup(content2, 'lxml')\n",
        "    return driver\n",
        "\n\n",
        "def get_base_info(driver):\n",
        "    base_table = {}\n",
        "    base_table['名称'] = driver.find_element_by_xpath(\"//div[@class='company_header_width ie9Style position-rel']/div\").text.split('我要认证')[0]\n",
        "    base_info = driver.find_element_by_xpath(\"//div[@class='company_header_interior pl10 pt10 pb10 position-rel company-claim-header-bc mt15']\")\n",
        "    base_table['电话'] = base_info.text.split('电话：')[1].split('邮箱：')[0]\n",
        "    base_table['邮箱'] = base_info.text.split('邮箱：')[1].split('\\n')[0]\n",
        "    base_table['网址'] = base_info.text.split('网址：')[1].split('地址')[0]\n",
        "    base_table['地址'] = base_info.text.split('地址：')[1].split('\\n')[0]\n",
        "    abstract = driver.find_element_by_xpath(\"//div[@class='sec-c2 over-hide']/script\")\n",
        "    base_table['简介'] = driver.execute_script(\"return arguments[0].textContent\", abstract).strip()\n",
        "    tabs = driver.find_elements_by_tag_name('table')\n",
        "\n",
        "    rows1 = tabs[0].find_elements_by_tag_name('tr')\n",
        "    base_table['法人代表'] = rows1[1].find_elements_by_tag_name('td')[0].text.split('\\n')[0]\n",
        "    base_table['注册资本'] = rows1[1].find_elements_by_tag_name('td')[1].text.split('\\n')[1]\n",
        "    base_table['注册时间'] = rows1[1].find_elements_by_tag_name('td')[1].text.split('\\n')[3]\n",
        "    base_table['公司状态'] = rows1[1].find_elements_by_tag_name('td')[1].text.split('\\n')[5]\n",
        "\n",
        "    rows2 = tabs[1].find_elements_by_tag_name('tr')\n",
        "    base_table['工商注册号'] = rows2[0].find_elements_by_tag_name('td')[1].text\n",
        "    base_table['统一信用代码'] = rows2[1].find_elements_by_tag_name('td')[1].text\n",
        "    base_table['纳税人识别号'] = rows2[2].find_elements_by_tag_name('td')[1].text\n",
        "    base_table['营业期限'] = rows2[3].find_elements_by_tag_name('td')[1].text\n",
        "    base_table['登记机关'] = rows2[4].find_elements_by_tag_name('td')[1].text\n",
        "\n",
        "    base_table['组织机构代码'] = rows2[0].find_elements_by_tag_name('td')[3].text\n",
        "    base_table['公司类型'] = rows2[1].find_elements_by_tag_name('td')[3].text\n",
        "    base_table['行业'] = rows2[2].find_elements_by_tag_name('td')[3].text\n",
        "    base_table['核准日期'] = rows2[3].find_elements_by_tag_name('td')[3].text\n",
        "    base_table['英文名称'] = rows2[4].find_elements_by_tag_name('td')[3].text\n",
        "\n",
        "    base_table['注册地址'] = rows2[5].find_elements_by_tag_name('td')[1].text.split('附近公司')[0]\n",
        "    base_table['经营范围'] = rows2[6].find_elements_by_tag_name('td')[1].text\n",
        "\n",
        "    return pd.DataFrame([base_table])\n",
        "\n\n",
        "def get_staff_info(driver):\n",
        "    staff_list = []\n",
        "    staff_info = driver.find_elements_by_xpath(\"//div[@class='in-block f14 new-c5 pt9 pl10 overflow-width vertival-middle new-border-right']\")\n",
        "    for i in range(len(staff_info)):\n",
        "        position = driver.find_elements_by_xpath(\"//div[@class='in-block f14 new-c5 pt9 pl10 overflow-width vertival-middle new-border-right']\")[i].text\n",
        "        person = driver.find_elements_by_xpath(\"//a[@class='overflow-width in-block vertival-middle pl15 mb4']\")[i].text\n",
        "        staff_list.append({'职位': position, '人员名称': person})\n",
        "    staff_table = pd.DataFrame(staff_list, columns=['职位', '人员名称'])\n",
        "    return staff_table\n",
        "\n\n",
        "def tryonclick(table):\n",
        "    # 测试是否有翻页\n",
        "    try:\n",
        "        # 找到有翻页标记\n",
        "        table.find_element_by_tag_name('ul')\n",
        "        onclickflag = 1\n",
        "    except Exception:\n",
        "        print(\"没有翻页\")\n",
        "        onclickflag = 0\n",
        "    return onclickflag\n",
        "\n\n",
        "def change_page(table, df):\n",
        "    PageCount = table.find_element_by_class_name('total').text\n",
        "    PageCount = re.sub(\"\\D\", \"\", PageCount)  # 使用正则表达式取字符串中的数字 ；\\D表示非数字的意思\n",
        "    for i in range(int(PageCount) - 1):\n",
        "        button = table.find_element_by_xpath(\".//li[@class='pagination-next  ']/a\")\n",
        "        driver.execute_script(\"arguments[0].click();\", button)\n",
        "        time.sleep(3)\n",
        "        df2 = get_table_info(table)\n",
        "        df = df.append(df2)\n",
        "    return df\n",
        "\n\n",
        "def get_table_info(table):\n",
        "    tab = table.find_element_by_tag_name('table')\n",
        "    df = pd.read_html('<table>' + tab.get_attribute('innerHTML') + '</table>')\n",
        "    if isinstance(df, list):\n",
        "        df = df[0]\n",
        "    if '操作' in df.columns:\n",
        "        df = df.drop(columns='操作')\n",
        "    return df\n",
        "\n\n",
        "def scrapy(driver):\n",
        "    tables = driver.find_elements_by_xpath(\"//div[contains(@id,'_container_')]\")\n",
        "\n",
        "    # 获取每个表格的名字\n",
        "    c = '_container_'\n",
        "    name = [0] * (len(tables) - 2)\n",
        "    # 生成一个独一无二的十六位参数作为公司标记，一个公司对应一个，需要插入多个数据表\n",
        "    id = keyword\n",
        "    table_dict = {}\n",
        "    for x in range(len(tables)-2):\n",
        "        name[x] = tables[x].get_attribute('id')\n",
        "        name[x] = name[x].replace(c, '')  # 可以用这个名称去匹配数据库\n",
        "        # 判断是表格还是表单\n",
        "        num = tables[x].find_elements_by_tag_name('table')\n",
        "\n",
        "        # 基本信息表table有两个\n",
        "        if len(num) > 1:\n",
        "            table_dict[name[x]] = get_base_info(driver)\n",
        "\n",
        "        elif name[x] in ['recruit', 'tmInfo']:\n",
        "            pass\n",
        "\n",
        "        #  单纯的表格\n",
        "        elif len(num) == 1:\n",
        "            df = get_table_info(tables[x])\n",
        "\n",
        "            onclickflag = tryonclick(tables[x])\n",
        "            # 判断此表格是否有翻页功能\n",
        "            if onclickflag == 1:\n",
        "                df = change_page(tables[x], df)\n",
        "\n",
        "            table_dict[name[x]] = df\n",
        "\n",
        "        # 表单样式\n",
        "        elif name[x] == 'staff':\n",
        "           table_dict[name[x]] = get_staff_info(driver)\n",
        "\n",
        "        else:\n",
        "            table_dict[name[x]] = pd.DataFrame()\n",
        "\n",
        "    table_dict['websiteRecords'] = get_table_info(tables[len(tables)-2])\n",
        "\n",
        "    return table_dict\n",
        "\n\n",
        "def gen_excel(table_dict, keyword):\n",
        "    with pd.ExcelWriter(path+keyword+'.xlsx') as writer:\n",
        "        for sheet_name in table_dict:\n",
        "            table_dict[sheet_name].to_excel(writer, sheet_name=sheet_name, index=None)\n",
        "\n\n",
        "if __name__ == '__main__':\n",
        "    url = 'https://www.tianyancha.com/login'\n",
        "    url1 = 'http://www.tianyancha.com/search?key=%s&checkFrom=searchBox' % keyword\n",
        "    username = '13488895246'\n",
        "    password = 'abcd1234'\n",
        "\n",
        "    driver = open_browser(url)\n",
        "    driver = log_in(driver)\n",
        "    driver = search_company(driver, url1)\n",
        "    table_dict = scrapy(driver)\n",
        "    gen_excel(table_dict, keyword)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "没有翻页\n",
            "没有翻页\n",
            "没有翻页\n",
            "没有翻页\n",
            "没有翻页\n",
            "没有翻页\n",
            "没有翻页\n",
            "没有翻页\n"
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.8.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}