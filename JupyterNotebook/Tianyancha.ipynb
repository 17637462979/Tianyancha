{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Loading Functions"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from fake_useragent import UserAgent\n",
        "import requests, time, re, math, openpyxl, datetime, os, shutil, psutil, platform, pyautogui, subprocess, webbrowser\n",
        "from tqdm import *\n",
        "import xlwings as xw\n",
        "from selenium import webdriver\n",
        "\n",
        "#from splinter import Browser\n",
        "#from pandas.io.json import json_normalize\n",
        "\n",
        "# Def get position function: 增加程序对数据源结构变化的稳定性\n",
        "def f_p(df, feature):\n",
        "    feature_list = df.iloc[:,0].get_values().tolist() # 第一列为特征名称，Index为连续自然数\n",
        "    return [i for i,x in enumerate(feature_list) if x == feature][0]\n",
        "\n",
        "# Def Check Nan Function\n",
        "# https://stackoverflow.com/questions/944700/how-can-i-check-for-nan-in-python\n",
        "def is_nan(x):\n",
        "    return isinstance(x, float) and math.isnan(x)\n",
        "\n",
        "# Get current file path for migration consistency\n",
        "path = os.getcwd().replace('\\\\','/') #r'%s' % os.getcwd().replace('\\\\','/')\n",
        "\n",
        "# 定义函数：从文本中根据数字类型提取Int或者Float数值\n",
        "def find_number(text):\n",
        "    if len(re.findall(r'\\.',text)) == 0:\n",
        "        return float(re.findall(r'\\d+',text.replace(\",\", \"\"))[0])\n",
        "    else:\n",
        "        return float(re.findall(r'\\d+\\.\\d+',text.replace(\",\", \"\"))[0])\n",
        "\n",
        "# Excel App Kill\n",
        "def kill_excel():\n",
        "    try:\n",
        "        for proc in psutil.process_iter():\n",
        "            if 'EXCEL.EXE' in proc.name() or 'Microsoft Excel' in proc.name():\n",
        "                proc.kill()\n",
        "    except Exception as e:\n",
        "        print (e)\n",
        "            \n",
        "# Chrome App Kill\n",
        "def kill_chrome():\n",
        "    try:\n",
        "        for proc in psutil.process_iter():\n",
        "            if 'chrome.exe' in proc.name():\n",
        "                proc.kill()\n",
        "    except Exception as e:\n",
        "        print (e)\n",
        "\n",
        "# Open WebPage in IE\n",
        "def ie_open(url):\n",
        "    ie = webbrowser.get(webbrowser.iexplore)\n",
        "    ie.open(url)\n",
        "    \n",
        "# 定义ChromeDriver\n",
        "# mac:把chromedriver放到/anaconda/bin\n",
        "if platform.system() == 'Darwin':\n",
        "    driver = webdriver.Chrome()\n",
        "else:\n",
        "    # Windows:把chromedriver放到下面的目录中\n",
        "    chromedriver = \"C:\\Program Files (x86)\\Google\\Chrome\\Application\\chromedriver.exe\"\n",
        "    os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
        "    #driver = webdriver.Chrome(chromedriver)\n",
        "    \n",
        "# Download File Common Function\n",
        "## 加入自主命名(根据列表)的功能\n",
        "def download_file(url, path):\n",
        "    local_filename = url.split('/')[-1]\n",
        "    # NOTE the stream=True parameter\n",
        "    r = requests.get(url, stream=True)\n",
        "    with open(local_filename, 'wb') as f:\n",
        "        for chunk in r.iter_content(chunk_size=1024): \n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "                #f.flush() commented by recommendation from J.F.Sebastian\n",
        "    shutil.move(local_filename,path+'/'+local_filename)\n",
        "    \n",
        "# Convert TimeString to DateTime\n",
        "\n",
        "# 定义天眼查爬虫\n",
        "def scrap(keyword):\n",
        "\n",
        "    def open_browser(url):\n",
        "        driver = webdriver.Chrome()\n",
        "        driver.get(url)\n",
        "        return driver\n",
        "\n\n",
        "    def log_in(driver):\n",
        "        # 模拟登陆\n",
        "        driver.find_element_by_xpath(\n",
        "            \".//*[@id='web-content']/div/div/div/div[2]/div/div[2]/div[2]/div[2]/div[2]/input\"). \\\n",
        "            send_keys(username)\n",
        "        driver.find_element_by_xpath(\n",
        "            \".//*[@id='web-content']/div/div/div/div[2]/div/div[2]/div[2]/div[2]/div[3]/input\"). \\\n",
        "            send_keys(password)\n",
        "        driver.find_element_by_xpath(\n",
        "            \".//*[@id='web-content']/div/div/div/div[2]/div/div[2]/div[2]/div[2]/div[5]\").click()\n",
        "        time.sleep(3)\n",
        "        return driver\n",
        "\n\n",
        "    def search_company(driver, url1):\n",
        "        driver.get(url1)\n",
        "        content = driver.page_source.encode('utf-8')\n",
        "        soup1 = BeautifulSoup(content, 'lxml')\n",
        "        time.sleep(3)\n",
        "        # company_name = soup1.find('a', class_=\"query_name sv-search-company f18 in-block vertical-middle\").get_text()\n",
        "\n",
        "        url2 = soup1.find('a', class_=\"query_name sv-search-company f18 in-block vertical-middle\").attrs['href']\n",
        "\n",
        "    #     ## 如果搜索有误，手工定义URL2地址\n",
        "    #     url2 = 'https://www.tianyancha.com/company/28472888'\n",
        "\n",
        "        driver.get(url2)\n",
        "        return driver\n",
        "\n",
        "    \n",
        "    def get_base_info(driver):\n",
        "        base_table = {}\n",
        "#         base_table['名称'] = driver.find_element_by_xpath(\"//div[@class='company_header_width ie9Style position-rel']/div\").text.split('我要认证')[0]\n",
        "#         try:\n",
        "#             base_info = driver.find_element_by_xpath(\"//div[@class='company_header_interior pl10 pt10 pb10 position-rel company-claim-header-bc mt15']\")\n",
        "#         except:\n",
        "#             base_info = driver.find_element_by_xpath(\"//div[@class='company_header_interior pl10 pt10 pb10 position-rel company-claim-header-bc ']\")\n",
        "#         base_table['电话'] = base_info.text.split('电话：')[1].split('邮箱：')[0]\n",
        "#         base_table['邮箱'] = base_info.text.split('邮箱：')[1].split('\\n')[0]\n",
        "#         base_table['网址'] = base_info.text.split('网址：')[1].split('地址')[0]\n",
        "#         base_table['地址'] = base_info.text.split('地址：')[1].split('\\n')[0]\n",
        "#         try:\n",
        "#             abstract = driver.find_element_by_xpath(\"//div[@class='sec-c2 over-hide']/script\")\n",
        "#             base_table['简介'] = driver.execute_script(\"return arguments[0].textContent\", abstract).strip()\n",
        "#         except:\n",
        "#             abstract = driver.find_element_by_xpath(\"//div[@class='sec-c2 over-hide']\")\n",
        "#             base_table['简介'] = driver.execute_script(\"return arguments[0].textContent\", abstract).strip()[3:]\n",
        "#         tabs = driver.find_elements_by_tag_name('table')\n",
        "\n",
        "#         rows1 = tabs[0].find_elements_by_tag_name('tr')\n",
        "#         if len(rows1[1].find_elements_by_tag_name('td')[0].text.split('\\n')[0]) < 2:\n",
        "#             base_table['法人代表'] = rows1[1].find_elements_by_tag_name('td')[0].text.split('\\n')[1]\n",
        "#         else:\n",
        "#             base_table['法人代表'] = rows1[1].find_elements_by_tag_name('td')[0].text.split('\\n')[0]\n",
        "#         base_table['注册资本'] = rows1[1].find_elements_by_tag_name('td')[1].text.split('\\n')[1]\n",
        "#         #base_table['注册时间'] = rows1[1].find_elements_by_tag_name('td')[1].text.split('\\n')[3]\n",
        "#         base_table['公司状态'] = rows1[1].find_elements_by_tag_name('td')[1].text.split('\\n')[5]\n",
        "\n",
        "#         rows2 = tabs[1].find_elements_by_tag_name('tr')\n",
        "#         base_table['工商注册号'] = rows2[0].find_elements_by_tag_name('td')[1].text\n",
        "#         base_table['统一信用代码'] = rows2[1].find_elements_by_tag_name('td')[1].text\n",
        "#         base_table['纳税人识别号'] = rows2[2].find_elements_by_tag_name('td')[1].text\n",
        "#         base_table['营业期限'] = rows2[3].find_elements_by_tag_name('td')[1].text\n",
        "#         base_table['登记机关'] = rows2[4].find_elements_by_tag_name('td')[1].text\n",
        "\n",
        "#         base_table['组织机构代码'] = rows2[0].find_elements_by_tag_name('td')[3].text\n",
        "#         base_table['公司类型'] = rows2[1].find_elements_by_tag_name('td')[3].text\n",
        "#         base_table['行业'] = rows2[2].find_elements_by_tag_name('td')[3].text\n",
        "#         #base_table['核准日期'] = rows2[3].find_elements_by_tag_name('td')[3].text\n",
        "#         base_table['英文名称'] = rows2[4].find_elements_by_tag_name('td')[3].text\n",
        "\n",
        "#         base_table['注册地址'] = rows2[5].find_elements_by_tag_name('td')[1].text.split('附近公司')[0]\n",
        "#         base_table['经营范围'] = rows2[6].find_elements_by_tag_name('td')[1].text\n",
        "\n",
        "    #     # 信息修正\n",
        "    #     base_table['注册时间'] = base_table['经营范围'].split['至'][0]\n",
        "    #     base_table['核准日期'] = base_table['经营范围'].split['至'][0]\n",
        "        print ('请手工更新注册时间/核准日期/注册资本！')\n",
        "\n",
        "        return pd.DataFrame([base_table])\n",
        "\n",
        "    \n",
        "    # 特殊处理：主要人员\n",
        "    ## staff_info定位不准？\n",
        "    def get_staff_info(driver):\n",
        "        staff_list = []\n",
        "        staff_info = driver.find_elements_by_xpath(\"//div[@class='in-block f14 new-c5 pt9 pl10 overflow-width vertival-middle new-border-right']\")\n",
        "        for i in range(len(staff_info)):\n",
        "            position = driver.find_elements_by_xpath(\"//div[@class='in-block f14 new-c5 pt9 pl10 overflow-width vertival-middle new-border-right']\")[i].text\n",
        "            person = driver.find_elements_by_xpath(\"//a[@class='overflow-width in-block vertival-middle pl15 mb4']\")[i].text\n",
        "            staff_list.append({'职位': position, '人员名称': person})\n",
        "        staff_table = pd.DataFrame(staff_list, columns=['职位', '人员名称'])\n",
        "        return staff_table\n",
        "\n",
        "    \n",
        "    # 特殊处理:上市公告\n",
        "    ## 加入类别搜索功能\n",
        "    def get_announcement_info(driver):\n",
        "        announcement_df = pd.DataFrame(columns=['序号','日期','上市公告','上市公告网页链接']) ## 子函数自动获取columns\n",
        "        ### 函数化\n",
        "        content = driver.page_source.encode('utf-8')\n",
        "        ## 能不能只Encode局部的driver\n",
        "        soup = BeautifulSoup(content, 'lxml')\n",
        "        announcement_info = soup.find('div',id='_container_announcement').find('tbody').find_all('tr')\n",
        "        for i in range(len(announcement_info)):\n",
        "            index = announcement_info[i].find_all('td')[0].get_text()\n",
        "            date = announcement_info[i].find_all('td')[1].get_text()\n",
        "            announcement = announcement_info[i].find_all('td')[2].get_text()\n",
        "            announcement_url = 'https://www.tianyancha.com' + announcement_info[i].find_all('td')[2].find('a')['href']\n",
        "            announcement_df = announcement_df.append({'序号':index,'日期':date,'上市公告':announcement,'上市公告网页链接':announcement_url}, ignore_index=True)\n",
        "        ###\n",
        "\n",
        "        ### 判断此表格是否有翻页功能:重新封装change_page函数\n",
        "        announcement_table = driver.find_element_by_xpath(\"//div[contains(@id,'_container_announcement')]\")\n",
        "        onclickflag = tryonclick(announcement_table)\n",
        "        if onclickflag == 1:\n",
        "            PageCount = announcement_table.find_element_by_class_name('total').text\n",
        "            PageCount = re.sub(\"\\D\", \"\", PageCount)  # 使用正则表达式取字符串中的数字 ；\\D表示非数字的意思\n",
        "            for i in range(int(PageCount) - 1):\n",
        "                button = announcement_table.find_element_by_xpath(\".//li[@class='pagination-next  ']/a\")\n",
        "                driver.execute_script(\"arguments[0].click();\", button)\n",
        "                ####################################################################################\n",
        "                time.sleep(change_page_interval)\n",
        "                ####################################################################################\n",
        "        ###\n",
        "                ### 函数化\n",
        "                content = driver.page_source.encode('utf-8')\n",
        "                ## 能不能只Encode局部的driver\n",
        "                soup = BeautifulSoup(content, 'lxml')\n",
        "                announcement_info = soup.find('div',id='_container_announcement').find('tbody').find_all('tr')\n",
        "                for i in range(len(announcement_info)):\n",
        "                    index = announcement_info[i].find_all('td')[0].get_text()\n",
        "                    date = announcement_info[i].find_all('td')[1].get_text()\n",
        "                    announcement = announcement_info[i].find_all('td')[2].get_text()\n",
        "                    announcement_url = 'https://www.tianyancha.com' + announcement_info[i].find_all('td')[2].find('a')['href']\n",
        "                    announcement_df = announcement_df.append({'序号':index,'日期':date,'上市公告':announcement,'上市公告网页链接':announcement_url}, ignore_index=True)\n",
        "                ###\n",
        "        return announcement_df\n",
        "\n",
        "    \n",
        "    def tryonclick(table): # table实质上是selenium WebElement\n",
        "        # 测试是否有翻页\n",
        "        ## 把条件判断写进tryoneclick中\n",
        "        try:\n",
        "            # 找到有翻页标记\n",
        "            table.find_element_by_tag_name('ul')\n",
        "            onclickflag = 1\n",
        "        except Exception:\n",
        "            print(\"没有翻页\") ## 声明表格名称: name[x] + \n",
        "            onclickflag = 0\n",
        "        return onclickflag\n",
        "\n",
        "    def tryontap(table):\n",
        "        # 测试是否有翻页\n",
        "        try:\n",
        "            table.find_element_by_xpath(\"//div[contains(@class,'over-hide changeTabLine f14')]\")\n",
        "            ontapflag = 1\n",
        "        except Exception:\n",
        "            print(\"没有时间切换页\") ## 声明表格名称: name[x] + \n",
        "            ontapflag = 0\n",
        "        return ontapflag\n",
        "\n",
        "    def change_page(table, df):\n",
        "        PageCount = table.find_element_by_class_name('total').text\n",
        "        PageCount = re.sub(\"\\D\", \"\", PageCount)  # 使用正则表达式取字符串中的数字 ；\\D表示非数字的意思\n",
        "        for i in range(int(PageCount) - 1):\n",
        "            button = table.find_element_by_xpath(\".//li[@class='pagination-next  ']/a\")\n",
        "            driver.execute_script(\"arguments[0].click();\", button)\n",
        "            ####################################################################################\n",
        "            time.sleep(change_page_interval) # 更新换页时间间隔,以应对反爬虫\n",
        "            ####################################################################################\n",
        "            df2 = get_table_info(table) ## 应该可以更换不同的get_XXXX_info\n",
        "            df = df.append(df2)\n",
        "        return df\n",
        "    \n",
        "    def change_tap(table, df):\n",
        "        TapCount = len(table.find_elements_by_tag_name('div'))\n",
        "        for i in range(int(TapCount) - 3):\n",
        "            button = table.find_elements_by_tag_name('div')[i+3]\n",
        "            driver.execute_script(\"arguments[0].click();\", button)\n",
        "            time.sleep(2)\n",
        "            df2 = get_table_info(table) ## 应该可以更换不同的get_XXXX_info\n",
        "     ##     df2['日期'] = table.find_elements_by_tag_name('div')[i+3].text\n",
        "            df = df.append(df2, ignore_index=True)\n",
        "     ## df = df.drop(columns=['序号'])\n",
        "        return df\n",
        "    \n",
        "    def get_table_info(table):\n",
        "        tab = table.find_element_by_tag_name('table')\n",
        "        df = pd.read_html('<table>' + tab.get_attribute('innerHTML') + '</table>')\n",
        "        if isinstance(df, list):\n",
        "            df = df[0]\n",
        "        if '操作' in df.columns:\n",
        "            df = df.drop(columns='操作')\n",
        "        return df\n",
        "\n",
        "    \n",
        "    def scrapy(driver):\n",
        "        # Waiting time for volatilityNum to load\n",
        "        time.sleep(2)\n",
        "        \n",
        "        tables = driver.find_elements_by_xpath(\"//div[contains(@id,'_container_')]\")\n",
        "\n",
        "        # 获取每个表格的名字\n",
        "        c = '_container_'\n",
        "        name = [0] * (len(tables) - 2)\n",
        "        # 生成一个独一无二的十六位参数作为公司标记，一个公司对应一个，需要插入多个数据表\n",
        "        id = keyword\n",
        "        table_dict = {}\n",
        "        for x in range(len(tables)-2):\n",
        "            name[x] = tables[x].get_attribute('id')\n",
        "            name[x] = name[x].replace(c, '')  # 可以用这个名称去匹配数据库\n",
        "            # 判断是表格还是表单\n",
        "            num = tables[x].find_elements_by_tag_name('table')\n",
        "\n",
        "            # 基本信息表：table有两个\n",
        "            if len(num) > 1: ##需要更好地设置baseinfo的判定条件\n",
        "                table_dict[name[x]] = get_base_info(driver)\n",
        "            \n",
        "            #########\n",
        "            # 排除列表：不同业务可以设置不同分类，实现信息的精准爬取\n",
        "            #########\n",
        "            elif name[x] in ['recruit', 'tmInfo', 'holdingCompany', 'bonus', 'invest', 'firmProduct', 'jingpin', \\\n",
        "                             'bid', 'taxcredit', 'certificate', 'patent', 'copyright', 'product', 'importAndExport', \\\n",
        "                             'copyrightWorks', 'wechat', 'websiteRecords', 'announcementcourt', 'lawsuit', 'court', \\\n",
        "                             'branch', 'touzi', 'judicialSale', 'bond', 'teamMember']:\n",
        "                pass\n",
        "\n",
        "#             # 公司高管的特殊处理\n",
        "#             elif name[x] == 'staff':\n",
        "#                 table_dict[name[x]] = get_staff_info(driver)\n",
        "            \n",
        "            # 公告的特殊处理：加入URL\n",
        "            elif name[x] == 'announcement':\n",
        "                table_dict[name[x]] = get_announcement_info(driver)                \n",
        "\n",
        "            #  单纯的表格进行信息爬取\n",
        "            ## 含头像的行未对齐\n",
        "            elif len(num) == 1:\n",
        "                df = get_table_info(tables[x])\n",
        "                onclickflag = tryonclick(tables[x])\n",
        "                ontapflag = tryontap(tables[x])\n",
        "                # 判断此表格是否有翻页功能\n",
        "                if onclickflag == 1:\n",
        "                    df = change_page(tables[x], df)\n",
        "            ##  if ontapflag == 1:\n",
        "            ##      df = change_tap(tables[x], df)\n",
        "                table_dict[name[x]] = df\n",
        "                \n",
        "            else:\n",
        "                table_dict[name[x]] = pd.DataFrame()\n",
        "\n",
        "        #table_dict['websiteRecords'] = get_table_info(tables[len(tables)-2])\n",
        "        return table_dict\n",
        "\n\n",
        "    def gen_excel(table_dict, keyword):\n",
        "        with pd.ExcelWriter(path+'/'+keyword+'.xlsx') as writer:\n",
        "            for sheet_name in table_dict:\n",
        "                table_dict[sheet_name].to_excel(writer, sheet_name=sheet_name, index=None)\n",
        "    \n",
        "    # 微信通知提醒进度：已进行到'131. XXXX; 35%',声明序号/名称/完成度;发送给自己\n",
        "    def notification_wechat():\n",
        "        pass\n",
        "\n",
        "    if __name__ == \"__main__\":\n",
        "        url = 'https://www.tianyancha.com/login'\n",
        "        url1 = 'http://www.tianyancha.com/search?key=%s&checkFrom=searchBox' % keyword\n",
        "\n",
        "        driver = open_browser(url)\n",
        "        driver = log_in(driver)\n",
        "        driver = search_company(driver, url1)\n",
        "        table_dict = scrapy(driver)\n",
        "        gen_excel(table_dict, keyword)\n",
        "        notification_wechat()\n",
        "\n",
        "        # 个性操作\n",
        "        os.makedirs(path+'/'+'clients'+'/'+ str(i+1) + '. ' + keyword + ' ' + keyword_list_name[i])\n",
        "        shutil.move(path+'/'+keyword+'.xlsx',path+'/'+'clients'+'/'+ str(i+1) + '. ' + keyword + ' ' + keyword_list_name[i] +'/'+keyword + ' ' + keyword_list_name[i] + '.xlsx')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "username = 'XXX' # 输入：天眼查注册名（手机号）\n",
        "password = 'XXX' # 输入：天眼查注册密码\n",
        "keyword = 'XXXX' # 输入: 查询公司的关键字"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execution"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "kill_chrome()\n",
        "\n",
        "try:\n",
        "    scrap(keyword)\n",
        "except Exception as e:\n",
        "    print (e)\n",
        "    break\n",
        "    \n",
        "kill_chrome()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}